---
title: "baysmacro"
output: html_document
date: "2024-03-01"
---

```{r}
Beta=.025
tao=0.025
alpha =0.3
psi=1/.169
gamma_pi=.469
gamma_w=.7111
lambda_w=.5
zeta_ps=.908
zeta_ws=0.737
sigma_L=2.4
sigma_c=1.353
h=0.573
phi=1.408
phi_uppercase=1/6.771
rbar_k=(1/Beta)-1+tao
ky=8.8
sigma_eta_C<- 0.336
Invy=22
Cy=0.6
Ky=Invy/tao
gy=1-Cy-Invy
r_pi_g=0.14
r_y=0.099
Ry_delta=0.159
rho=0.961
r_pi=1.684
rho_el=0.889
rho_ea=0.823
rho_eb=0.855
rho_G=0.949
rho_pi=0.924
 rh_i=0.927
rho_er=0
r_k_star <- (1 / Beta) - 1 + tao
rho_lamdaw=0
rho_q=0
rho_lamda_p=0
rho_L <-   0.9
sigma_e_L=3.52
sigma_e_a=.598
sigma_e_b=.336
sigma_G=.325
sigma_pi_bar=.017
sigma_er=0.081
sigma_ei=0.085
sigma_lamada_p=.16
sigma_lamda_w=.289
sigma_e_q=.604
sigma_e_i <- 0.085
sigma_e_c<- 0.336
alpha_k <- 0.3 
sigma_e_p <- 0.16 # Standard deviation for price markup shocks
sigma_e_w <- 0.289 # Standard deviation for wage markup shocks
sigma_e_q <- 0.604 # Standard deviation for equity price markup shocks


```
```{r}
# Define parameters for the distributions
mean_inverse_gamma <- 0.25
mean_inverse_gamma_pi_star <- 0.05
degrees_of_freedom <- 2
mean_beta <- 0.85
sd_beta <- 0.1

# For the Beta distribution parameters, convert mean and standard deviation to alpha and beta parameters
alpha_beta <- ((1 - mean_beta) / sd_beta^2 - 1 / mean_beta) * mean_beta^2
beta_beta <- alpha_beta * (1 / mean_beta - 1)

# Define the Inverse-Gamma distribution for the standard errors of the innovations
sigma_e <- rgamma(1, shape = 1 / degrees_of_freedom, scale = 1 / (mean_inverse_gamma * degrees_of_freedom))
sigma_e_pi_star <- rgamma(1, shape = 1 / degrees_of_freedom, scale = 1 / (mean_inverse_gamma_pi_star * degrees_of_freedom))

# Convert from gamma to inverse gamma since R does not have a direct inverse gamma function
sigma_e <- 1 / sigma_e
sigma_e_pi_star <- 1 / sigma_e_pi_star

# Define the Beta distribution for the persistence parameters of the AR(1) processes
rho_ar1 <- rbeta(1, alpha_beta, beta_beta)
```

```{r}
calculate_ema_4th_order <- function(data, n=4) {
  # Ensure data is in correct format (numeric vector)
  if (!is.numeric(data)) {
    stop("Data must be a numeric vector.")
  }

  alpha <- 2 / (n + 1)
  ema <- numeric(length(data))
  ema[1] <- data[1]  # Initialize the first EMA value to the first data point
  
  for (t in 2:length(data)) {
    ema[t] <- alpha * data[t] + (1 - alpha) * ema[t-1]
  }
  
  # To calculate expected next value, we simply apply the formula one more time assuming last value repeats
  expected_next_ema <- alpha * data[length(data)] + (1 - alpha) * ema[length(ema)]
  return(list(ema = ema, expected_next = expected_next_ema))
}



# Now, apply the calculate_ema_4th_order function to this lagged series
# Assuming you have initialized your dataframe and it's being updated elsewhere in your simulation

calculate_ema_4th_order_for_df <- function(df, column_name, n=4) {
  # Extract the column data based on column_name
  data <- df[[column_name]]
  
  # Filter out NA values that arise due to lagging
  data <- na.omit(data)
  
  # Apply the EMA calculation
  ema_result <- calculate_ema_4th_order(data, n)
  
  # Return the result
  return(ema_result)
}


```


```{r}
# Define the parameters for the Beta distribution based on the given mean and standard deviation
mean_beta <- 0.85
sd_beta <- 0.1
alpha_beta <- ((1 - mean_beta) / sd_beta^2 - 1 / mean_beta) * mean_beta^2
beta_beta <- alpha_beta * (1 / mean_beta - 1)


```


```{r}
library(readxl)
# Attempt to read the file without the leading directory path
averageweeklyproductionhours <- read_excel("averageweeklyproductionhours.xls")
employment=read_excel("Employment .xls")
gdpdeflator =read_excel("gdpdeflator.xlsx")
population =read_excel("population .xlsx")
investment =read_excel("fixedprivateinvestment .xls")
fedfunds=read_excel("FEDFUNDS.xls")
personalconsumption=read_excel("personalconsumption.xlsx")
realGDP=read_excel("realgdp.xlsx")
compensation =read_excel("compensation .xlsx")
GDPPOT <- read_excel("GDPPOT.xls")
hours2xls <- read_excel("hours3xls.xls")


```
```{r}
# List of your data frames
df_list <- list(averageweeklyproductionhours, employment, gdpdeflator, population, investment, fedfunds, personalconsumption, realGDP,compensation,GDPPOT,hours2xls )

# Function to convert the first column to Date and the second to numeric
convert_columns <- function(df) {
  df[[1]] <- as.Date(df[[1]], format = "%Y-%m-%d") # Adjust format as necessary
  df[[2]] <- as.numeric(df[[2]])
  return(df)
}

# Apply the function to each data frame in the list
converted_df_list <- lapply(df_list, convert_columns)

# If you want to replace the original data frames in your environment with the converted ones:
names(converted_df_list) <- c("averageweeklyproductionhours", "employment", "gdpdeflator", "population", "investment", "fedfunds", "personalconsumption", "realGDP","compensation","GDPPOT","hours")
list2env(converted_df_list, envir = .GlobalEnv)

```
```{r}
# Assuming the converted data frames are stored in 'converted_df_list' and all have a common date column named 'Date'
# If the date column has different names across data frames, you'll need to rename them to be consistent first

# Example of renaming the first column to 'Date' for all data frames if needed
converted_df_list <- lapply(converted_df_list, function(df) {
  names(df)[1] <- 'Date'
  return(df)
})

# Merging all data frames on the 'Date' column
merged_df <- Reduce(function(x, y) merge(x, y, by = 'Date', all = TRUE), converted_df_list)

# The 'all = TRUE' argument ensures that all rows from each data frame are kept in the merged data frame, 
# even if there are missing matches in the 'Date' column from any of the data frames

# View the merged data frame
View(merged_df)

```
```{r}

# Assuming your data frame is named df
merged_df <- merged_df[387:722, ]


```

```{r}
# Assuming 'merged_df' is your merged data frame
cleaned_df <- na.omit(merged_df)

# View the cleaned data frame
View(cleaned_df)

```
```{r}
library(dplyr)
cleaned_df<- cleaned_df %>%
mutate(potential_gdp = GDPPOT* 1000000000)
```

```{r}

# library(lubridate)
final <- cleaned_df %>%
  mutate(
    Output_growth = c(NA, 100 * diff(log(`real gdp` / population))),
    potential_gdp = c(NA, 100 * diff(log(potential_gdp / population))),
    Consumption_growth = c(NA, 100 * diff(log((PCE / `gdp deflator`) / population))),
    Investment_growth = c(NA, 100 * diff(log((fpi / `gdp deflator`) / population))),
    Wage_growth = c(NA, 100 * diff(log(compensation / `gdp deflator`))),
    Hours = ((1+hours)^1/4)+1,
    Inflation = c(NA, 100 * diff(log(`gdp deflator`))),
    Ffr = FEDFUNDS / 4
  )

```


```{r}
# Real-time running average calculation
real_time_running_average <- function(data, i, window_size) {
    if (i < window_size) {
        # If less data than window size, calculate mean of available data
        return(mean(data[1:i]))
    } else {
        # Calculate running average of the window size ending at current index i
        return(mean(data[(i-window_size+1):i]))
    }
}
```

```{r}
final=final[2:110,]
```

```{r}
# Load necessary library
library(dplyr)

# Assuming `final` is your dataframe and already exists in your environment
# Extract the last 9 columns into a new dataframe
last_9_vars <- final[, (ncol(final)-7):ncol(final)]

# Use the existing correlation matrix
cor_matrix <- cor(final[, (ncol(final)-7):ncol(final)])
```
```{r}
# Normalize the weights using the correlation matrix
normalized_weights <- sweep(cor_matrix, 2, colSums(cor_matrix), FUN = "/")

# Pre-allocate a matrix to store t+1 estimates for each row
t_plus_1_estimates <- matrix(NA, nrow = nrow(last_9_vars) - 1, ncol = ncol(last_9_vars))
colnames(t_plus_1_estimates) <- paste0(colnames(last_9_vars), "_t_plus_1")

# Loop through each variable (column)
for (j in 1:ncol(last_9_vars)) {
    # Loop through each row except the last one
    for (i in 1:(nrow(last_9_vars) - 1)) {
        # Check if the current variable is Hours, Inflation, or Ffr
        if (colnames(last_9_vars)[j] %in% c("Hours", "Inflation", "Ffr")) {
            # For Hours, Inflation, and Ffr, t+1 equals the previous value
            t_plus_1_estimates[i, j] <- last_9_vars[i, j]
        } else {
            # Use the current value directly and apply the normalized correlation weight
            weighted_value <- last_9_vars[i, j] * normalized_weights[j, j]

            # Generate random epsilon with conditional randomness
            epsilon <- if (colnames(last_9_vars)[j] %in% c("Inflation", "Ffr")) {
                runif(1, -6, 6)  # +/- 6% for Inflation and Ffr
            } else {
                runif(1, -0.4, 0.4)  # +/- 0.4% for other variables
            }

            # Calculate the t+1 value for this specific element by adding epsilon
            t_plus_1_estimates[i, j] <- weighted_value + epsilon
        }
    }
}

# Convert the matrix to a dataframe for easier handling
t_plus_1_estimates_df <- as.data.frame(t_plus_1_estimates)

# Append the t+1 estimates as new columns to the original `final` dataframe
final_with_predictions <- cbind(final[-nrow(final), ], t_plus_1_estimates_df)

# Print the final dataframe with predictions
print(final_with_predictions)

```


```{r}
# Calculate the number of rows in the dataframe
num_rows <- nrow(final_with_predictions)

# Add this as a new column to the dataframe
final_with_predictions$num_rows <- num_rows
```


```{r}
# Initialize the dataframe with the first 4rhows set to 1
my_data <- data.frame(
   
   time = 1:num_rows,
    
    K_hat = rep(0, num_rows),
    r_k_star = rep(0, num_rows),
    
    Q_hat = rep(0, num_rows),
    pi_bar = rep(1, num_rows),
    
    epsilon_C = rep(1, num_rows),
    epsilon_Q = rep(1, num_rows),
    epsilon_I = rep(1, num_rows),
    epsilon_W = rep(1, num_rows),
    epsilon_R = rep(1, num_rows),
    epsilon_Pi = rep(1, num_rows),
    epsilon_L = rep(1, num_rows),
    epsilon_G = rep(1, num_rows),
    
    epsilon_pitwo = rep(1, num_rows)
   
)

     
# Assigning the appropriate columns from final_with_predictions to the new variables in my_data
my_data$C_hat_plus_1 = final_with_predictions$Consumption_growth_t_plus_1
my_data$I_hat_plus_1 = final_with_predictions$Investment_growth_t_plus_1
my_data$Y_hat_plus_1 = final_with_predictions$Output_growth_t_plus_1
my_data$Pi_hat_plus_1 = final_with_predictions$Inflation_t_plus_1
my_data$R_hat_plus_1 = final_with_predictions$Ffr_t_plus_1
my_data$L_hat_plus_1= final_with_predictions$Hours_t_plus_1
my_data$w_hat_plus_1=final_with_predictions$Wage_growth_t_plus_1
my_data$C_hat=final_with_predictions$Consumption_growth
my_data$I_hat=final_with_predictions$Investment_growth
my_data$Y_hat=final_with_predictions$Output_growth
my_data$Pi_hat=final_with_predictions$Inflation
my_data$R_hat=final_with_predictions$Ffr
my_data$L_hat=final_with_predictions$Hours
my_data$w_hat=final_with_predictions$Wage_growth
my_data$potential_gdp=final_with_predictions$potential_gdp
my_data$inflationtaget=final_with_predictions$inf
     
```
```{r}
# Before the loop, call the calculate_ema_4th_order function to get expected values
for   (i in 2:nrow(my_data)){
    # Update lagged values
    my_data$C_hat_lag1[i] <- my_data$C_hat[i-1]
    my_data$I_hat_lag1[i] <- my_data$I_hat[i-1]
    my_data$Q_hat_lag1[i] <- my_data$Q_hat[i-1] # Noting the case sensitivity
    my_data$C_expect_lag[i] = my_data$C_expect[i-1]
    my_data$Pi_hat_lag1[i] <- my_data$Pi_hat[i-1]
    my_data$K_hat_lag1[i] <- my_data$K_hat[i-1]
    my_data$W_hat_lag1[i] <- my_data$W_hat[i-1]
     my_data$k_hat_lag1[i] <- my_data$k_hat[i-1]
    my_data$Y_hat_lag1[i] <- my_data$Y_hat[i-1]
    my_data$YP_hat_lag1[i] <- my_data$YP_hat[i-1]
     my_data$L_hat_lag1[i] <- my_data$L_hat[i-1]
    my_data$L_hat_lag1[i] <- my_data$L_hat[i-1]
  
# Generate new shock value for epsilon_c for the currentrhow
    eta_c <- rnorm(1, mean = 0, sd = sigma_eta_C)
    
# Simulate a persistence parameter from the Beta distribution
    rho_c<- rbeta(1, alpha_beta, beta_beta)
     my_data$epsilon_C[i] <- rho_c * my_data$epsilon_C[i-1] + eta_c
       # Generate new shock value for epsilon_q for the current row
     epsilon_Q<- rnorm(1, mean = 0, sd = sigma_e_q)
       my_data$epsilon_Q[i] <- epsilon_Q
       eta_I<- rnorm(1, mean = 0, sd = sigma_e_i)
       rho_q<- rbeta(1, alpha_beta, beta_beta)
       my_data$epsilon_I[i] <- rho_q * my_data$epsilon_I[i-1] + eta_I
      
       epsilon_W <- rnorm(1, mean = 0, sd = sigma_e_w)
       my_data$epsilon_W[i]=epsilon_W
      epsilon_p <- rnorm(1, mean = 0, sd = sigma_e_p)
      my_data$epsilon_Pi[i]=epsilon_p
      
        rho_pi<- rbeta(1, alpha_beta, beta_beta)
        eta_pitwo<- rnorm(1, mean = 0, sd = sigma_pi_bar)
       my_data$epsilon_pitwo[i] <- rho_pi * my_data$epsilon_pitwo[i-1] + eta_pitwo
        eta_g<- rnorm(1, mean = 0, sd = sigma_e_q)
        rho_g<- rbeta(1, alpha_beta, beta_beta)
       my_data$epsilon_G[i] <- rho_g * my_data$epsilon_G[i-1] + eta_g
       eta_l<- rnorm(1, mean = 0, sd = sigma_e_L)
        rho_l<- rbeta(1, alpha_beta, beta_beta)
       my_data$epsilon_L[i] <- rho_l * my_data$epsilon_G[i-1] + eta_l
       epsilon_R<- rnorm(1, mean = 0, sd = sigma_er)
       my_data$epsilon_R[i]=epsilon_R
     # Update pi_bar using the running average of Pi_hat
    my_data$pi_bar[i] <- real_time_running_average(my_data$Pi_hat, i, window_size = 5)  # window size is an example, adjust as needed
 

 #hours_shocked[t] = -wage_growth_shocked[t] + (1 + psi) * ffr_shocked[t] + kapital_shocked[t-1]

# my_data$I_hat[i] = (1 / (1 + Beta)) * my_data$I_hat[i-1] +(Beta / (1 + Beta)) *my_data$I_hat_plus_1[i]+((1/phi_uppercase)/(1+Beta))*my_data$Q_hat[i]+my_data$epsilon_I[t]
#my_data$Q_hat[i] <- phi_uppercase * (1 + Beta) * (
 # my_data$I_hat[i] - 
  #(1 / (1 + Beta)) * my_data$I_hat[i-1] - 
  #(Beta / (1 + Beta)) * my_data$I_hat_plus_1[i] - 
 #my_data$epsilon_I[t]
#)
        
  # Output gap equation
my_data$Q_hat[i] = -(my_data$R_hat[i] - my_data$Pi_hat_plus_1[i]) +
       ((1-tao) / (1 - tao + r_k_star)) * (phi_uppercase * (1 + Beta) * (
  my_data$I_hat[i] - (1 / (1 + Beta)) * my_data$I_hat[i-1] - 
  (Beta / (1 + Beta)) * my_data$I_hat_plus_1[i] - my_data$epsilon_I[i]
)) +(r_k_star / (1 - tao + r_k_star)) * my_data$R_hat_plus_1[i] + my_data$epsilon_Q[i]



 
 my_data$K_hat[i]=(1-tao)*my_data$K_hat[i-1]+tao*my_data$I_hat[i-1]+tao*my_data$epsilon_I[i-1]
   
    
  my_data$r_k_star[i]=my_data$R_hat[i]
    
    }
```


```{r}
library(dplyr)

# Assuming 'final' is your data frame
my_data <- my_data %>% mutate(inflationtarget = 0.35)
```
```{r}

```


```{r}
library(rstan)
```

```{r}
# Re-check the lengths to see if they meet the expected length
lengths <- sapply(my_data, length)
print(lengths)

# If lengths are correct, proceed to create the Stan data list
T <- num_rows

# Combine vectors into a new list for Stan
data_list <- list(
  T = T,  # 'T' is a single integer, not a vector
  sigma_Pi_hat = 0.4543148,
  sigma_C_hat = 0.7461217,
  sigma_I_hat = 1.856414,
  sigma_R_hat = 0.9289912,
  sigma_W_hat = 0.676194,
  sigma_L_hat = 2.52645,
  epsilon_C = my_data$epsilon_C[1:T],
  epsilon_Q = my_data$epsilon_Q[1:T],
  epsilon_I = my_data$epsilon_I[1:T],
  epsilon_PI = my_data$epsilon_Pi[1:T],
  epsilon_G = my_data$epsilon_G[1:T],
  epsilon_R = my_data$epsilon_R[1:T],
  epsilon_W = my_data$epsilon_W[1:T],
  r_k_star = my_data$r_k_star[1:T],
  inflationtarget=my_data$inflationtarget[1:T],
  potential_gdp=my_data$potential_gdp[1:T],
  pi_bar = my_data$pi_bar[1:T],
  kapital = my_data$K_hat[1:T],
  q= my_data$Q_hat[1:T],
  epsilon_pitwo = my_data$epsilon_pitwo[1:T],
  epsilon_L = my_data$epsilon_L[1:T],
  consumption_growth_vector = my_data$C_hat[1:T],
 investment_growth_vector = my_data$I_hat[1:T],
 output_growth_vector= my_data$Y_hat[1:T],
  inflation_vector = my_data$Pi_hat[1:T],
  ffr_vector= my_data$R_hat[1:T],
  hours_vector= my_data$L_hat[1:T],
   wage_growth_vector= my_data$w_hat[1:T],
  shock_time = 20,  # Example time point
  shock_value = 0  # Example shock value
)


library(V8)
```
```{stan output.var=model}
data {
  int<lower=1> T; // Number of time points
  real<lower=0> sigma_Pi_hat;   // SD for inflation_vector
  real<lower=0> sigma_C_hat;    // SD for consumption_growth_vector
  real<lower=0> sigma_I_hat;    // SD for investment_growth_vector
  real<lower=0> sigma_R_hat;    // SD for ffr_vector
  real<lower=0> sigma_W_hat;    // SD for wage_growth_vector
  real<lower=0> sigma_L_hat;    // SD for hours_vector
  vector[T] consumption_growth_vector ;    // Observed data
  vector[T] output_growth_vector;
  vector[T]  potential_gdp;
  vector[T] investment_growth_vector;
  
  
  vector[T] inflation_vector;
  vector[T] ffr_vector;
  vector[T] kapital;
  vector[T] q;
  vector[T]  r_k_star;
  vector[T] inflationtarget;
  vector[T] epsilon_L;
  vector[T] epsilon_pitwo;
   int<lower=1, upper=T> shock_time; // Time of the shock
  real shock_value; // Magnitude of the shock
    // Standard deviation for eta_c
} 

parameters {
 vector[T] expected_Pi_hat_next;
  vector[T] expected_C_hat_next;
  vector[T] expected_I_hat_next;
  vector[T] expected_R_hat_next;

  vector[T] expected_L_hat_next;

  // Define the initial means for the expected terms
  real mu_Pi_hat;  // Initial mean for expected_Pi_hat_next
  real mu_C_hat;   // Initial mean for expected_C_hat_next
  real mu_I_hat;   // Initial mean for expected_I_hat_next
  real mu_R_hat;   // Initial mean for expected_R_hat_next
  real mu_W_hat;   // Initial mean for expected_W_hat_next
  real mu_L_hat;   // Initial mean for expected_L_hat_next
 vector[T] epsilon_C;
  vector[T] epsilon_I;
  vector[T] epsilon_R;
   
 
  
  vector[T] epsilon_PI;
  vector[T] epsilon_Q;
  vector[T] epsilon_G;
  
    real<lower=0.99, upper=1> Beta; // Given mean is 0.025, the range would be truncated because Beta cannot be negative
  real<lower=0.025, upper=0.035> tao;
  real<lower=0, upper=0.8> alpha; // Mean=0.3, so range is 0.3±0.5, lower bound truncated at 0
  real<lower=0, upper=1> psi; // Mean=1/.169, requires calculating the actual value and then ±0.5, truncating bounds as necessary
  real<lower=0.3, upper=0.5> gamma_pi; // Mean=0.469, so range is 0.469±0.5, upper bound truncated at 1
  real<lower=0.5, upper=1> gamma_w; // Mean=0.7111, so range is 0.7111±0.5, upper bound truncated at 1
 
 
    
  real<lower=0.35, upper=0.75> lambda_w;
  real<lower=0.85, upper=1> zeta_ps;
  real<lower=0.5, upper=1> zeta_ws;
  real<lower=1.8, upper=2.4> sigma_L;
  real<lower=0.853, upper=1.87> sigma_c;
  real<lower=0, upper=1> h;
  real<lower= 2.5, upper=5.5> phi;
  real<lower=0.9, upper=1.25> phi_uppercase; // Mean=1/6.771, requires calculating the actual value and then ±0.5, truncating bounds as necessary
  real<lower=0, upper=1> rbar_k; // Depends on Beta, the range might need to be dynamically calculated
  real<lower=8.3, upper=9.3> Ky;
  real<lower=0, upper=0.1116> sigma_eta_C;  
  real<lower=0.15, upper=0.25> Invy;
  real<lower=0.3, upper=0.9> Cy; // Mean=0.6, so range is 0.6±0.5, upper bound truncated at 1
    // Declare epsilon parameters to be estimated
   
 
  real<lower=0.13, upper=0.29> gy; // Computed from 1-Cy-Invy, so range needs to be calculated based on those values
  real<lower=0.3, upper=0.84> r_pi;
  real<lower=0, upper=0.599> r_y;
  real<lower=0, upper=0.659> Ry_delta;
   real<lower=0.8, upper=1> rho;
  real<lower=0.7, upper=1> rho_el;
  real<lower=0.7, upper=1> rho_ea;
  real<lower=0.7, upper=1> rho_eb;
  real<lower=0.65, upper=1> rho_G;
  real<lower=0.7, upper=1> rho_pi;
  real<lower=0.65, upper=1> rh_i;
  
  real<lower=0,upper =0.4> kappa;
 // real<lower=0> rho_er; // Since rho_er=0, it is set as the lower bound
  real<lower=0, upper=1> rho_lamdaw; // Since rho_lamdaw=0, it is set as the lower bound
  real<lower=0, upper=1> rho_q; // Since rho_q=0, it is set as the lower bound
  real<lower=0, upper=1> rho_lamda_p; // Since rho_lamda_p=0, it is set as the lower bound
  
  // r_k_star is computed from Beta and tao, and will need to have a dynamic range based on those values.
 
  // rho_L has a given value of 0.9, the range would be 0.4 to 1 since it can't exceed 1
  real<lower=0.4, upper=1> rho_L;
   real<lower=0> sigma_fiscal_inflation;
  real<lower=0> sigma_fiscal_unfunded_debt;
  real<lower=0> sigma_bond_price;
  real<lower=0> sigma_government_debt;
  real<lower=0> sigma_output;
  // Existing parameters
  real<lower=0, upper=1> psi_F;       // Persistence of fiscal inflation ψ^F
  real<lower=0> delta_b_F;            // Sensitivity parameter δ_b^F
  real<lower=0> b_param;              // Debt parameter b
  real<lower=0> rho_M;                // Return parameter ρ_M
  real<lower=0> R_short_term;         // Short-term nominal interest rate R
  real<lower=0> inv_beta;             // Inverse discount factor β⁻¹
  vector[T] epsilon_TF;               // Fiscal shocks ε_t^{TF}
  vector[T] epsilon_tau;              // Fiscal policy shocks ε_t^τ
  real<lower=0, upper=1> rho_tau;     // Fiscal policy persistence parameter
  real delta_b;                       // Sensitivity to debt difference δ_b
  real delta_y;                       // Sensitivity to output gap δ_y
  real delta_dy;// Sensitivity to output change δ_{dy}
  vector[T] epsilon_pi_F;
  // Latent variables
  vector[T] fiscal_inflation;         // Fiscal inflation π_t^F
  vector[T] fiscal_unfunded_debt;     // Unfunded debt b_t^F
  vector[T] R_b;                      // Return on long-term bond R^b_{t-1,t}
  vector[T] P_bond;                   // Bond prices P_t^b
  vector[T] government_debt;          // Government debt b_t
  vector[T] tau;// Primary surplus τ_t
  vector[T] bond_price_shock;
}
  transformed parameters {
  vector[T] output_growth_shocked;
  vector[T] consumption_growth_shocked;
  vector[T] investment_growth_shocked;
 
 
  vector[T] inflation_shocked;
  vector[T] ffr_shocked;
  vector[T] kapital_shocked;
  vector[T] q_shocked;
  vector[T] r_k_star_shocked;
  vector[T] inflationtarget_shocked;
  vector[T] potential_gdp_shocked;

  // Shocked expected values
  vector[T] expected_Pi_hat_next_shocked;
  vector[T] expected_C_hat_next_shocked;
  vector[T] expected_I_hat_next_shocked;
  vector[T] expected_R_hat_next_shocked;
 
  vector[T] expected_L_hat_next_shocked;
   // Vectors to store shocked variables
  vector[T] fiscal_inflation_shocked;
  vector[T] fiscal_unfunded_debt_shocked;
  vector[T] government_debt_shocked;
  vector[T] tau_shocked;
  vector[T] R_b_shocked;
  vector[T] P_bond_shocked;
  
  // Initialize variables with initial values
  fiscal_inflation_shocked[1] = fiscal_inflation[1];
  fiscal_unfunded_debt_shocked[1] = fiscal_unfunded_debt[1];
  government_debt_shocked[1] = government_debt[1];
  tau_shocked[1] = tau[1];
  P_bond_shocked[1] = P_bond[1];
  
  // Define the shocks to apply
  vector[T] epsilon_TF_shocked;
  vector[T] epsilon_tau_shocked;
  vector[T] epsilon_pi_F_shocked;
  vector[T] bond_price_shock_shocked;
   // Initialize with original vectors
  output_growth_shocked = output_growth_vector;
  consumption_growth_shocked = consumption_growth_vector;
  investment_growth_shocked = investment_growth_vector;
  
  inflation_shocked = inflation_vector;
  ffr_shocked = ffr_vector;
  kapital_shocked = kapital;
  q_shocked = q;
  r_k_star_shocked = r_k_star;
  inflationtarget_shocked = inflationtarget;
  potential_gdp_shocked = potential_gdp;

  // Initialize the shocked expected values
  expected_Pi_hat_next_shocked = expected_Pi_hat_next;
  expected_C_hat_next_shocked = expected_C_hat_next;
  expected_I_hat_next_shocked = expected_I_hat_next;
  expected_R_hat_next_shocked = expected_R_hat_next;
 
  expected_L_hat_next_shocked = expected_L_hat_next;

// Apply a 30% decrease in output growth at the specified time
 for (t in shock_time:min(shock_time + 4, T)) {
  inflation_shocked[t] = inflation_shocked[t] ;
}


  // Propagate the shock through other series
  for (t in (shock_time + 1):T) {
    // Fiscal policy rule with shock
real output_gap_shocked = output_growth_shocked[t] - potential_gdp_shocked[t];
real output_change_shocked = output_growth_shocked[t] - output_growth_shocked[t-1]; // Adjusted to use 'output_growth_shocked'

  ffr_shocked[t] = inflation_shocked[t-1] +
                 0.5 * ( output_gap_shocked) +
                 0.5 * (inflation_shocked[t-1] - inflationtarget_shocked[t-1]) + inflationtarget_shocked[t] + epsilon_R[t];

consumption_growth_shocked[t] = (h / (1 + h)) * consumption_growth_shocked[t-1] +
                                (1 / (1 + h)) * expected_C_hat_next[t] +
                                 -
                                ((1 - h) / ((1 + h)) * sigma_c) * (ffr_shocked[t] - inflation_shocked[t-1]) +
                                ((1 - h) / ((1 + h) * sigma_c)) * epsilon_C[t];

q_shocked[t] = -(ffr_shocked[t] - inflation_shocked[t-1]) +
               ((1-tao) / (1 - tao + ffr_shocked[t])) * q_shocked[t-1] +
               (ffr_shocked[t] / (1 - tao + ffr_shocked[t])) * ffr_shocked[t-1] + epsilon_Q[t];

investment_growth_shocked[t] = (1 / (1 + Beta)) * investment_growth_shocked[t-1] +
                               (Beta / (1 + Beta)) * expected_I_hat_next[t] +
                               ((1/phi_uppercase)/(1+Beta)) * q_shocked[t] + epsilon_I[t];

kapital_shocked[t] =(1-tao)*kapital_shocked[t-1]+tao*investment_growth_shocked[t-1]+tao*epsilon_I[t-1] ;


output_growth_shocked[t] = (1 - (tao * Ky) - gy) * consumption_growth_shocked[t] +
                           (tao * Ky) * investment_growth_shocked[t] + gy * tau_shocked[t];


// Final inflation shocked equation
inflation_shocked[t] = kappa * (output_growth_shocked[t] - potential_gdp_shocked[t]) + Beta * expected_Pi_hat_next_shocked[t]; 



// Fiscal inflation with shock
    fiscal_inflation_shocked[t] = psi_F * fiscal_inflation_shocked[t-1] + epsilon_pi_F_shocked[t];
    
    // Unfunded debt with shock
    fiscal_unfunded_debt_shocked[t] = (inv_beta - delta_b_F) * fiscal_unfunded_debt_shocked[t-1]
                                      - b_param * (inv_beta - psi_F) * fiscal_inflation_shocked[t]
                                      + epsilon_TF_shocked[t];
    
    // Bond price with shock
    P_bond_shocked[t] = P_bond_shocked[t-1] + bond_price_shock_shocked[t];
    
    // Return on long-term bond with shock
    R_b_shocked[t-1] = (rho_M / ffr_vector[t]) * P_bond_shocked[t] - P_bond_shocked[t-1];
    
    // Government debt with shock
    government_debt_shocked[t] = inv_beta * government_debt_shocked[t-1]
                                 + b_param * inv_beta * (R_b_shocked[t-1] - output_growth_shocked[t] + output_growth_shocked[t-1] - inflation_shocked[t])
                                 - tau_shocked[t];
    
    // Fiscal policy rule with shock
    
    tau_shocked[t] = rho_tau * tau_shocked[t-1]
                     + (1 - rho_tau) * (delta_b * (government_debt_shocked[t-1] - fiscal_unfunded_debt_shocked[t-1])
                     + delta_b_F * fiscal_unfunded_debt_shocked[t-1]
                     + delta_y * output_gap_shocked)
                     + delta_dy * output_change_shocked
                     + epsilon_tau_shocked[t];

    

   
  }
}

model {
  // Priors
  psi_F ~ beta(2, 2);
  kappa ~ normal(.2,.07);
  delta_b_F ~ normal(0, 1);
  b_param ~ normal(0, 1);
  rho_M ~ normal(0, 1);
 //R_short_term ~ normal(1.02, 0.01);
  inv_beta ~ normal(1.02, 0.01);
  rho_tau ~ beta(2, 2);
  delta_b ~ normal(0, 1);
  delta_y ~ normal(0, 1);
  delta_dy ~ normal(0, 1);
  epsilon_TF ~ normal(0, 0.1);
  epsilon_tau ~ normal(0, 0.1);
  epsilon_pi_F ~ normal(0, 0.1);
  bond_price_shock ~ normal(0, 0.1);
  
   // Define the inverse gamma distributions for sigma parameters using the values from the image
  sigma_fiscal_inflation ~ inv_gamma(0.1, 2.0);  // for σ_p (if this corresponds to inflation shock)
  sigma_fiscal_unfunded_debt ~ inv_gamma(1.0, 2.0);  // for σ_b
  sigma_bond_price ~ inv_gamma(0.1, 2.0);  // for σ_g (adjust according to what you want to represent)
  sigma_government_debt ~ inv_gamma(1, 2.0);  // for σ_debt
  // Initial conditins
  fiscal_inflation[1] ~ normal(0, 0.1);
  fiscal_unfunded_debt[1] ~ normal(0, 0.1);
  government_debt[1] ~ normal(0, 0.1);
  tau[1] ~ normal(0, 0.1);
  P_bond[1] ~ normal(1, 0.1);
  // Priors for parameters based on the provided table
  phi ~ normal(4.00, 1.50);
  //sigma_c ~ normal(1.50, 0.37);
  h ~ beta(6, 14);  // Beta parameters calculated from mean and standard deviation
  zeta_ws ~ beta(12.25, 12.25);

// Mean=0.5, SD=0.10 implies alpha=beta
  //sigma_e_L ~ normal(2.00, 0.75);
   zeta_ps ~ beta(12.25, 12.25);
 // Mean=0.5, SD=0.10 implies alpha=beta
  lambda_w ~ beta( 5.055556, 5.055556);  // Mean=0.5, SD=0.15 implies alpha=beta
 
  psi ~ beta(5.5556, 5.5556);

// Mean=0.5, SD=0.15 implies alpha=beta
  phi_uppercase ~ normal(1.25, 0.12);
  r_pi ~ normal(1.50, 0.25);
  
  r_y ~ normal(0.12, 0.05);
  Ry_delta ~ normal(0.12, 0.05);
  
  rbar_k ~ normal(0.40, 0.10);
  alpha ~ normal(0.30, 0.05);
   // Prior for c_epsilon
  epsilon_C ~ normal(0.2235108, 0.5110157);

  // Prior for g_epsilon
  epsilon_G ~ normal(0.2881206, 0.902025);

  // Prior for i_epsilon
  epsilon_I~ normal(-0.01233631, 0.2190598);

 

  // Prior for pi_epsilon
  epsilon_PI ~ normal(0.02746, 0.1849336);

  // Prior for r_epsilon
   epsilon_R ~ normal(0.009779291, 0.1262237); 
  
   epsilon_Q ~ normal(0.7000578, 0.7411022);

   rho ~ beta(2.625, 2.625);
  rho_el ~ beta(2.625, 2.625);
  rho_ea ~ beta(2.625, 2.625);
  rho_eb ~ beta(2.65, 2.625);
  rho_G ~ beta(2.65, 2.625);
  rho_pi ~ beta(2.625, 2.625);
  rh_i ~ beta(2.625, 2.625);
  rho_L ~ beta(2.625, 2.625);
  // Likelihood
  
  
  // Set priors for the means using the estimated values
  mu_Pi_hat ~ normal(0.7511204, sigma_Pi_hat);
  mu_C_hat ~ normal(0.5452631, sigma_C_hat);
  mu_I_hat ~ normal( 0.4092956, sigma_I_hat);
  mu_R_hat ~ normal( 1.598727, sigma_R_hat);
  
  mu_L_hat ~ normal( 1.585092, sigma_L_hat);

  // Stochastic processes for expected terms
  expected_Pi_hat_next[1] ~ normal(mu_Pi_hat, sigma_Pi_hat);
  expected_C_hat_next[1] ~ normal(mu_C_hat, sigma_C_hat);
  expected_I_hat_next[1] ~ normal(mu_I_hat, sigma_I_hat);
  expected_R_hat_next[1] ~ normal(mu_R_hat, sigma_R_hat);
  
  expected_L_hat_next[1] ~ normal(mu_L_hat, sigma_L_hat);

  for (t in 3:T) {
    expected_Pi_hat_next[t] ~ normal(expected_Pi_hat_next[t-1], sigma_Pi_hat);
    expected_C_hat_next[t] ~ normal(expected_C_hat_next[t-1], sigma_C_hat);
    expected_I_hat_next[t] ~ normal(expected_I_hat_next[t-1], sigma_I_hat);
    expected_R_hat_next[t] ~ normal(expected_R_hat_next[t-1], sigma_R_hat);
   
    expected_L_hat_next[t] ~ normal(expected_L_hat_next[t-1], sigma_L_hat);

  
    ffr_vector[t] ~ normal(
 inflation_vector[t-1] +
                 0.5 * ( potential_gdp[t]-output_growth_vector[t]) +
                 0.5 * (inflation_vector[t-1] - inflationtarget[t-1]) + inflationtarget[t] + epsilon_R[t] ,
  0.9289912
);

     // Assuming rho_c and eta_c are arrays generated in 'generated quantities'
  real part1 = (h / (1 + h)) * consumption_growth_vector[t-1];
real part2 = (1 / (1 + h)) * expected_C_hat_next[t];

real part4 = -((1 - h) / ((1 + h)) * sigma_c) * (ffr_vector[t] - expected_Pi_hat_next[t]);
real part5 = ((1 - h) / ((1 + h) * sigma_c)) * epsilon_C[t];

consumption_growth_vector[t] ~ normal(part1 + part2 +  part4 + part5, 0.7461217);

   
     
     //r_k_star~ (-(kapital[t]-hours_vector[t])-wage_growth_vector[t],)
     //Output gap equation
 q[t] ~ normal(-(ffr_vector[t] - inflation_vector[t]) +
      ((1-tao) / (1 - tao + ffr_vector[t])) *q[t-1]+
    (r_k_star[t] / (1 - tao + ffr_vector[t])) * ffr_vector[t-1]+epsilon_Q[t],0.7226538);
    
    investment_growth_vector[t] ~ normal((1 / (1 + Beta)) * investment_growth_vector[t-1] +(Beta / (1 + Beta)) *expected_I_hat_next[t]+((1/phi_uppercase)/(1+Beta))*q[t]+epsilon_I[t], 1.856414);
      
   kapital[t] ~ normal((1-tao)*kapital[t-1]+tao*investment_growth_vector[t-1]+tao*epsilon_I[t-1],0.2299672 );

    
  
   
   output_growth_vector[t] ~ normal((1 - (tao * Ky) - gy) * consumption_growth_vector[t] +
    (tao * Ky) * investment_growth_vector[t] +
    gy * tau[t] +  // Include fiscal policy response
    epsilon_G[t],0.7320224);
      
// Breaking down the calculation into parts
 
// Combine parts
  inflation_vector[t] ~ normal(kappa * (output_growth_vector[t] - potential_gdp[t]) + Beta * expected_Pi_hat_next[t],0.4543148);
   
    // Fiscal inflation dynamics
    fiscal_inflation[t] ~ normal(psi_F * fiscal_inflation[t-1] + epsilon_pi_F[t], sigma_fiscal_inflation);
  


    // Unfunded debt dynamics
    fiscal_unfunded_debt[t] ~ normal(
      (inv_beta - delta_b_F) * fiscal_unfunded_debt[t-1] - b_param * (inv_beta - psi_F) * fiscal_inflation[t] + epsilon_TF[t],
      sigma_fiscal_unfunded_debt
    );

    // Bond price dynamics
    P_bond[t] ~ normal(P_bond[t-1] + bond_price_shock[t], sigma_bond_price);

    // Return on long-term bond
    R_b[t-1] = (rho_M / ffr_vector[t-1]) * P_bond[t] - P_bond[t-1];

    // Government debt dynamics
    government_debt[t] ~ normal(
      inv_beta * government_debt[t-1] + b_param * inv_beta * (R_b[t-1] - output[t] + output[t-1] - inflation[t]) - tau[t],
      sigma_government_debt
    );

    // Fiscal policy rule
   // Fiscal policy rule with shock
real output_gap = output_growth_vector[t] - potential_gdp[t];
real output_change = output_growth[t] - output_growth[t-1]; // Adjusted to use 'output_growth_shocked'


    tau[t] ~ normal(
      rho_tau * tau[t-1]
      + (1 - rho_tau) * (delta_b * (government_debt[t-1] - fiscal_unfunded_debt[t-1]) + delta_b_F * fiscal_unfunded_debt[t-1] + delta_y * output_gap)
      + delta_dy * output_change
      + epsilon_tau[t],
      sigma_tau
    );
    
    
  }
   }
 
 generated quantities {
  // Output vectors for the shocked variables
  vector[T] output_growth_shocked_output;
  vector[T] consumption_growth_shocked_output;
  vector[T] investment_growth_shocked_output;
  
  vector[T] inflation_shocked_output;
  vector[T] ffr_shocked_output;
  vector[T] expected_Pi_hat_next_shocked_output;
  vector[T] expected_I_hat_next_shocked_output;
  vector[T] expected_R_hat_next_shocked_output;
     
  vector[T] expected_L_hat_next_shocked_output;
  vector[T] expected_C_hat_next_shocked_output;

  // Assigning the transformed parameters to the output variables
  output_growth_shocked_output = output_growth_shocked;
  consumption_growth_shocked_output = consumption_growth_shocked;
  investment_growth_shocked_output = investment_growth_shocked;
  
  
  inflation_shocked_output = inflation_shocked;
  ffr_shocked_output = ffr_shocked;
  expected_Pi_hat_next_shocked_output = expected_Pi_hat_next_shocked;
  expected_I_hat_next_shocked_output = expected_I_hat_next_shocked;
   expected_R_hat_next_shocked_output = expected_R_hat_next_shocked;
 
  expected_L_hat_next_shocked_output = expected_L_hat_next_shocked;
  expected_C_hat_next_shocked_output = expected_C_hat_next_shocked;
}
```


```{r}
fit <- sampling(model, data = data_list, algorithm = "NUTS", iter = 2000, chains = 1, control = list(max_treedepth = 15))

```
```{r}
fit <- sampling(model, data = data_list, algorithm = "Fixed_param", iter = 1, chains = 1)

```


```{r}
fit <- sampling(model, data =data_list , chains = 4, iter = 6000, warmup = 1000)

```
```{r}
 # Load necessary libraries
library(bayesplot)
library(gridExtra)
library(ggplot2)

# Generate trace plots for each parameter at index [2]
trace1 <- mcmc_trace(fit, pars = "expected_Pi_hat_next[2]") + ggtitle("expected_Pi_hat_next[2]")
trace2 <- mcmc_trace(fit, pars = "expected_C_hat_next[2]") + ggtitle("expected_C_hat_next[2]")
trace3 <- mcmc_trace(fit, pars = "expected_I_hat_next[2]") + ggtitle("expected_I_hat_next[2]")
trace4 <- mcmc_trace(fit, pars = "expected_R_hat_next[2]") + ggtitle("expected_R_hat_next[2]")
trace5 <- mcmc_trace(fit, pars = "expected_W_hat_next[2]") + ggtitle("expected_W_hat_next[2]")
trace6 <- mcmc_trace(fit, pars = "expected_L_hat_next[2]") + ggtitle("expected_L_hat_next[2]")
trace7 <- mcmc_trace(fit, pars = "output_growth_shocked[2]") + ggtitle("output_growth_shocked[2]")
trace8 <- mcmc_trace(fit, pars = "consumption_growth_shocked[2]") + ggtitle("consumption_growth_shocked[2]")
trace9 <- mcmc_trace(fit, pars = "investment_growth_shocked[2]") + ggtitle("investment_growth_shocked[2]")

# Arrange plots in a grid with 3 columns
grid.arrange(trace1, trace2, trace3, 
             trace4, trace5, trace6, 
             trace7, trace8, trace9, 
             ncol = 3)

```

```{r}
# Load necessary libraries
library(bayesplot)
library(gridExtra)
library(ggplot2)

# Generate trace plots for each parameter at index [2]
trace1 <- mcmc_trace(fit, pars = "expected_Pi_hat_next[2]") + ggtitle("expected_Pi_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace2 <- mcmc_trace(fit, pars = "expected_C_hat_next[2]") + ggtitle("expected_C_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace3 <- mcmc_trace(fit, pars = "expected_I_hat_next[2]") + ggtitle("expected_I_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace4 <- mcmc_trace(fit, pars = "expected_R_hat_next[2]") + ggtitle("expected_R_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace5 <- mcmc_trace(fit, pars = "expected_W_hat_next[2]") + ggtitle("expected_W_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace6 <- mcmc_trace(fit, pars = "expected_L_hat_next[2]") + ggtitle("expected_L_hat_next[2]") + theme(plot.title = element_text(size = 10))
trace7 <- mcmc_trace(fit, pars = "output_growth_shocked[2]") + ggtitle("output_growth_shocked[2]") + theme(plot.title = element_text(size = 10))
trace8 <- mcmc_trace(fit, pars = "consumption_growth_shocked[2]") + ggtitle("consumption_growth_shocked[2]") + theme(plot.title = element_text(size = 10))
trace9 <- mcmc_trace(fit, pars = "investment_growth_shocked[2]") + ggtitle("investment_growth_shocked[2]") + theme(plot.title = element_text(size = 10))
trace10 <- mcmc_trace(fit, pars = "wage_growth_shocked[2]") + ggtitle("wage_growth_shocked[2]") + theme(plot.title = element_text(size = 10))
trace11 <- mcmc_trace(fit, pars = "hours_shocked[2]") + ggtitle("hours_shocked[2]") + theme(plot.title = element_text(size = 10))
trace12 <- mcmc_trace(fit, pars = "inflation_shocked[2]") + ggtitle("inflation_shocked[2]") + theme(plot.title = element_text(size = 10))
trace13 <- mcmc_trace(fit, pars = "ffr_shocked[2]") + ggtitle("ffr_shocked[2]") + theme(plot.title = element_text(size = 10))
trace14 <- mcmc_trace(fit, pars = "kapital_shocked[2]") + ggtitle("kapital_shocked[2]") + theme(plot.title = element_text(size = 10))
trace15 <- mcmc_trace(fit, pars = "q_shocked[2]") + ggtitle("q_shocked[2]") + theme(plot.title = element_text(size = 10))
trace16 <- mcmc_trace(fit, pars = "r_k_star_shocked[2]") + ggtitle("r_k_star_shocked[2]") + theme(plot.title = element_text(size = 10))
trace17 <- mcmc_trace(fit, pars = "inflationtarget_shocked[2]") + ggtitle("inflationtarget_shocked[2]") + theme(plot.title = element_text(size = 10))
trace18 <- mcmc_trace(fit, pars = "potential_gdp_shocked[2]") + ggtitle("potential_gdp_shocked[2]") + theme(plot.title = element_text(size = 10))

# Arrange the first set of plots in a grid with 5 columns
grid.arrange(trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, trace10, 
             trace11, trace12, trace13, trace14, trace15, trace16, trace17, trace18, 
             ncol = 5)  # Adjust the number of columns (5) for better spacing

```

```{r}
# Extract samples from the fitted model
samples <- rstan::extract(fit)

# Check if the variables exist and have correct dimensions
print(names(samples))
print(dim(samples$output_growth_shocked))
print(dim(samples$consumption_growth_shocked))
print(dim(samples$investment_growth_shocked))
print(dim(samples$wage_growth_shocked))
print(dim(samples$hours_shocked))
print(dim(samples$inflation_shocked))
print(dim(samples$ffr_shocked))


```
```{r}
# Calculate the mean and credible intervals for each shocked variable

# Output Growth
mean_output_growth_shocked <- apply(samples$output_growth_shocked_output, 2, mean)
lower_credible_interval_output <- apply(samples$output_growth_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_output <- apply(samples$output_growth_shocked_output, 2, quantile, probs = 0.975)

# Consumption Growth
mean_consumption_growth_shocked <- apply(samples$consumption_growth_shocked_output, 2, mean)
lower_credible_interval_consumption <- apply(samples$consumption_growth_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_consumption <- apply(samples$consumption_growth_shocked_output, 2, quantile, probs = 0.975)

# Investment Growth
mean_investment_growth_shocked <- apply(samples$investment_growth_shocked_output, 2, median)
lower_credible_interval_investment <- apply(samples$investment_growth_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_investment <- apply(samples$investment_growth_shocked_output, 2, quantile, probs = 0.975)

# Wage Growth
mean_wage_growth_shocked <- apply(samples$wage_growth_shocked_output, 2, mean)
lower_credible_interval_wage <- apply(samples$wage_growth_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_wage <- apply(samples$wage_growth_shocked_output, 2, quantile, probs = 0.975)
# potential_gdp
potential_gdp<- apply(samples$potential_gdp_shocked, 2, mean)
lower_credible_interval_hours <- apply(samples$potential_gdp_shocked, 2, quantile, probs = 0.025)
upper_credible_interval_hours <- apply(samples$potential_gdp_shocked, 2, quantile, probs = 0.975)
# Hours
mean_hours_shocked <- apply(samples$hours_shocked_output, 2, mean)
lower_credible_interval_hours <- apply(samples$hours_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_hours <- apply(samples$hours_shocked_output, 2, quantile, probs = 0.975)

# Inflation
mean_inflation_shocked <- apply(samples$inflation_shocked_output, 2, mean)
lower_credible_interval_inflation <- apply(samples$inflation_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_inflation <- apply(samples$inflation_shocked_output, 2, quantile, probs = 0.975)

# Federal Funds Rate
mean_ffr_shocked <- apply(samples$ffr_shocked_output, 2, mean)
lower_credible_interval_ffr <- apply(samples$ffr_shocked_output, 2, quantile, probs = 0.025)
upper_credible_interval_ffr <- apply(samples$ffr_shocked_output, 2, quantile, probs = 0.975)





```


```{r}
library(ggplot2)
library(gridExtra)

# Create a function to plot a variable with its credible intervals
plot_shocked_variable <- function(original, mean_shocked, lower_ci, upper_ci, variable_name) {
  data <- data.frame(
    Time = 1:length(original),
    Original = original,
    Mean_Shocked = mean_shocked,
    Lower_CI = lower_ci,
    Upper_C_I = upper_ci
  )
  
  ggplot(data, aes(x = Time)) +
    geom_line(aes(y = Original), color = "blue", linetype = "dashed") +
    geom_line(aes(y = Mean_Shocked), color = "red") +
    geom_ribbon(aes(ymin = Lower_CI, ymax = Upper_C_I), fill = "red", alpha = 0.2) +
    labs(title = paste("Original and Shocked", variable_name, "Series"), x = "Time", y = variable_name) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 10),
      axis.title.x = element_text(size = 8),
      axis.title.y = element_text(size = 8),
      axis.text = element_text(size = 6),
      legend.title = element_text(size = 8),
      legend.text = element_text(size = 6)
    )
}

# Plot each variable
plot_list <- list(
  plot_shocked_variable(data_list$output_growth_vector, mean_output_growth_shocked, lower_credible_interval_output, upper_credible_interval_output, "Output Growth"),
  plot_shocked_variable(data_list$consumption_growth_vector, mean_consumption_growth_shocked, lower_credible_interval_consumption, upper_credible_interval_consumption, "Consumption Growth"),
  plot_shocked_variable(data_list$investment_growth_vector, mean_investment_growth_shocked, lower_credible_interval_investment, upper_credible_interval_investment, "Investment Growth"),
  plot_shocked_variable(data_list$wage_growth_vector, mean_wage_growth_shocked, lower_credible_interval_wage, upper_credible_interval_wage, "Wage Growth"),
  plot_shocked_variable(data_list$hours_vector, mean_hours_shocked, lower_credible_interval_hours, upper_credible_interval_hours, "Hours"),
  plot_shocked_variable(data_list$inflation_vector, mean_inflation_shocked, lower_credible_interval_inflation, upper_credible_interval_inflation, "Inflation"),
  plot_shocked_variable(data_list$ffr_vector, mean_ffr_shocked, lower_credible_interval_ffr, upper_credible_interval_ffr, "Federal Funds Rate")
)

# Arrange the plots in a grid
grid.arrange(grobs = plot_list, ncol = 2)

```
```{r}
# Create a function to plot a variable with its credible intervals and dynamic y-axis limits
plot_shocked_variable <- function(original, mean_shocked, lower_ci, upper_ci, variable_name) {
  # Ensure all vectors have the same length
  min_length <- min(length(original), length(mean_shocked), length(lower_ci), length(upper_ci))
  
  original <- original[1:min_length]
  mean_shocked <- mean_shocked[1:min_length]
  lower_ci <- lower_ci[1:min_length]
  upper_ci <- upper_ci[1:min_length]
  
  # Calculate dynamic y-axis limits based on original and mean shocked values
  ymin <- min(c(original, mean_shocked), na.rm = TRUE) - 1
  ymax <- max(c(original, mean_shocked), na.rm = TRUE) + 1
  
  # Create data frame for plotting
  data <- data.frame(
    Time = 1:min_length,
    Original = original,
    Mean_Shocked = mean_shocked,
    Lower_CI = lower_ci,
    Upper_C_I = upper_ci
  )
  
  # Create the plot
  ggplot(data, aes(x = Time)) +
    geom_line(aes(y = Original), color = "blue", linetype = "dashed") +
    geom_line(aes(y = Mean_Shocked), color = "red") +
    geom_ribbon(aes(ymin = Lower_CI, ymax = Upper_C_I), fill = "red", alpha = 0.2) +
    labs(title = paste("Original and Shocked", variable_name, "Series"), x = "Time", y = variable_name) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 10),  # Adjust title size
      axis.title.x = element_text(size = 8),  # Adjust x-axis title size
      axis.title.y = element_text(size = 8),  # Adjust y-axis title size
      axis.text = element_text(size = 6),  # Adjust axis text size
      legend.title = element_text(size = 8),  # Adjust legend title size
      legend.text = element_text(size = 6)  # Adjust legend text size
    ) +
    ylim(ymin, ymax)  # Set dynamic y-axis limits
}

# Generate the list of plots with dynamic y-axis limits and length consistency
plot_list <- list(
  plot_shocked_variable(data_list$output_growth_vector, mean_output_growth_shocked, lower_credible_interval_output, upper_credible_interval_output, "Output Growth"),
  plot_shocked_variable(data_list$consumption_growth_vector, mean_consumption_growth_shocked, lower_credible_interval_consumption, upper_credible_interval_consumption, "Consumption Growth"),
  plot_shocked_variable(data_list$investment_growth_vector, mean_investment_growth_shocked, lower_credible_interval_investment, upper_credible_interval_investment, "Investment Growth"),
  plot_shocked_variable(data_list$wage_growth_vector, mean_wage_growth_shocked, lower_credible_interval_wage, upper_credible_interval_wage, "Wage Growth"),
  plot_shocked_variable(data_list$hours_vector, mean_hours_shocked, lower_credible_interval_hours, upper_credible_interval_hours, "Hours"),
  plot_shocked_variable(data_list$inflation_vector, mean_inflation_shocked, lower_credible_interval_inflation, upper_credible_interval_inflation, "Inflation"),
  plot_shocked_variable(data_list$ffr_vector, mean_ffr_shocked, lower_credible_interval_ffr, upper_credible_interval_ffr, "Federal Funds Rate")
)

# Arrange the plots in a grid with 2 columns, and adjust the spacing
grid.arrange(grobs = plot_list, ncol = 2, padding = unit(1, "line"))


```

```{r}


# Extract parameters
params <- as.array(fit)


# List of variable names corresponding to the state transition matrix
variable_names <- c(
  "Beta", "tao", "alpha", "psi", "gamma_pi", "gamma_w",
  "lambda_w", "zeta_ps", "zeta_ws", "sigma_L",
  "sigma_c", "h", "phi", "phi_uppercase", "rbar_k", "Ky",
  "sigma_eta_C", "Invy", "Cy", "gy",
  "r_pi", "r_y", "Ry_delta", "rho",
  "rho_el", "rho_ea", "rho_eb", "rho_G", "rho_pi", "rh_i",
  "rho_lamdaw", "rho_q", "rho_lamda_p", "rho_L", "output_growth_shocked", "consumption_growth_shocked",
  "investment_growth_shocked", "wage_growth_shocked", "hours_shocked", "potential_gdp_shocked",
  "inflation_shocked", "ffr_shocked", "kapital_shocked", "q_shocked", "r_k_star_shocked", "inflationtaget_shocked",
  "output_growth_shocked_output", "consumption_growth_shocked_output", "investment_growth_shocked_output", "wage_growth_shocked_output",
  "hours_shocked_output", "inflation_shocked_output", "ffr_shocked_output", "lp__"
)

# Construct the state transition matrix A as you did earlier (without parameters that don't exist)
A <- matrix(c(
  params[1, 1, "Beta"], params[1, 1, "tao"], params[1, 1, "alpha"], params[1, 1, "psi"], 
  params[1, 1, "gamma_pi"], params[1, 1, "gamma_w"],
  params[1, 1, "lambda_w"], params[1, 1, "zeta_ps"], params[1, 1, "zeta_ws"], 
  params[1, 1, "sigma_L"], params[1, 1, "sigma_c"], params[1, 1, "h"],
  params[1, 1, "phi"], params[1, 1, "phi_uppercase"], params[1, 1, "rbar_k"], 
  params[1, 1, "Ky"], params[1, 1, "sigma_eta_C"], params[1, 1, "Invy"],
  params[1, 1, "Cy"], params[1, 1, "gy"], params[1, 1, "r_pi"], params[1, 1, "r_y"], 
  params[1, 1, "Ry_delta"], params[1, 1, "rho"], params[1, 1, "rho_el"], params[1, 1, "rho_ea"], 
  params[1, 1, "rho_eb"], params[1, 1, "rho_G"], params[1, 1, "rho_pi"], params[1, 1, "rh_i"],
  params[1, 1, "rho_lamdaw"], params[1, 1, "rho_q"], params[1, 1, "rho_lamda_p"], 
  params[1, 1, "rho_L"]
), nrow = 6, byrow = TRUE)
# Ensure A is square by matching the number of rows and columns
if (nrow(A) != ncol(A)) {
  stop("The state transition matrix A is not square.")
}

# Calculate eigenvalues
eig_vals <- eigen(A)$values
 
# Calculate eigenvalues
eig_vals <- eigen(A)$values

# Identify and map eigenvalues with magnitudes greater than 1 to their variable names
unstable_eigenvalues <- eig_vals[abs(eig_vals) > 1]
unstable_variables <- variable_names[abs(eig_vals) > 1]

# Print unstable eigenvalues and corresponding variables
print("Unstable eigenvalues and corresponding variables (magnitude > 1):")
print(data.frame(variable = unstable_variables, eigenvalue = unstable_eigenvalues))

# Output all eigenvalues for inspection
print("All eigenvalues:")
print(eig_vals)
```


```{r}
library(bayesplot)
```
```{r}
setwd("C:/Users/gealy/OneDrive/Documents/New folder (2)")
getwd()

```
```{r}
# Assuming 'fit' is your Stan model object
summary_stats <- summary(fit)$summary

# Convert the matrix to a data frame where rows are parameters and columns are summary statistics
df_summary_stats <- as.data.frame(summary_stats)

# Set the row names as a column if needed
df_summary_stats$parameter <- rownames(df_summary_stats)

# Now df_summary_stats is a data frame with each parameter as a row and statistics as columns
print(df_summary_stats)

```
```{r}
library(dplyr)
library(tidyr)

# Step 1: Select only the `mean` and `parameter` columns (explicitly use dplyr::select)
df_cleaned <- df_summary_stats %>%
  dplyr::select(mean, parameter)

# Step 2: Separate the `parameter` column into two parts: the name and the number inside the brackets
df_separated <- df_cleaned %>%
  separate(parameter, into = c("param_name", "number"), sep = "\\[|\\]", convert = TRUE)

# Step 3: Filter out rows without a number and remove duplicates
df_filtered <- df_separated %>%
  filter(!is.na(number)) %>%    # Remove rows where 'number' is NA
  distinct()                    # Remove duplicate rows

# Step 4: Pivot the data frame to make the `param_name` the columns and the `number` the rows
df_final <- df_filtered %>%
  pivot_wider(names_from = param_name, values_from = mean)

# Step 5: Replace any NA values in the final data frame with 1 across all columns
df_final <- df_final %>%
  mutate(across(everything(), ~ replace_na(.x, 1)))

# Print the final resulting data frame
print(df_final)


```
```{r}
# Assuming df_final contains columns for all the necessary variables
# Beta, expected_W_hat_next, wage_growth_shocked, inflationtarget_shocked, inflation_shocked,
# gamma_w, zeta_ws, lambda_w, sigma_L, hours_shocked, consumption_growth_shocked, h, epsilon_L, epsilon_W

df_final <- df_final %>%
  mutate(
    # Part 1: Expected future wage growth
    part1_wage = (Beta / (1 + Beta)) * expected_W_hat_next,
    
    # Part 2: Lagged wage growth (previous period)
    part2_wage = (1 / (1 + Beta)) * lag(wage_growth_shocked_final, 1),
    
    # Part 3: Impact of inflation differences
    part3_inflation = (Beta / (1 + Beta)) * (lag(inflationtarget_shocked, 1) - inflation_shocked),
    
    # Part 4: Adjustment for combined inflation and wage-related term
    part4_inflation_wage = ((1 + (Beta * gamma_w)) / (1 + Beta)) * (lag(inflationtarget_shocked, 1) - inflation_shocked),
    
    # Part 5: Complex adjustment factor
    adjustment_factor = (1 / (1 + Beta)) * ((1 - (Beta * zeta_ws) * (1 - zeta_ws)) /
                        (1 + ((1 - lambda_w) * sigma_L) / lambda_w) * zeta_ws),
    
    # Part 6: Complex term involving wage growth, hours worked, and consumption growth
    complex_term = adjustment_factor * (lag(wage_growth_shocked, 1) - (sigma_L * hours_shocked) -
                    (1 / (1 - h)) * (consumption_growth_shocked - (h * lag(consumption_growth_shocked, 1)))),
    
    # Error terms
    #error_term = epsilon_L + epsilon_W,
    
    # Final wage growth shocked equation
    wage_growth_shocked_final = part1_wage + part2_wage + part3_inflation - part4_inflation_wage - complex_term #+ error_term
  )
  

```



```{r}
# Assuming the parameters from your model are in the samples object
beta <- mean(samples$beta)
tao <- mean(samples$tao)
alpha <- mean(samples$alpha)
psi <- mean(samples$psi)
gamma_pi <- mean(samples$gamma_pi)
gamma_w <- mean(samples$gamma_w)
lambda_w <- mean(samples$lambda_w)
zeta_ps <- mean(samples$zeta_ps)
zeta_ws <- mean(samples$zeta_ws)
sigma_L <- mean(samples$sigma_L)
sigma_c <- mean(samples$sigma_c)
h <- mean(samples$h)
phi <- mean(samples$phi)
phi_uppercase <- mean(samples$phi_uppercase)
rbar_k <- mean(samples$rbar_k)
Ky <- mean(samples$Ky)
sigma_eta_C <- mean(samples$sigma_eta_C)
Invy <- mean(samples$Invy)
Cy <- mean(samples$Cy)
gy <- mean(samples$gy)
r_pi <- mean(samples$r_pi)
r_y <- mean(samples$r_y)
r_delta <- mean(samples$r_delta)
rho <- mean(samples$rho)
rho_el <- mean(samples$rho_el)
rho_ea <- mean(samples$rho_ea)
rho_eb <- mean(samples$rho_eb)
rho_G <- mean(samples$rho_G)
rho_pi <- mean(samples$rho_pi)
rh_i <- mean(samples$rh_i)
rho_lamdaw <- mean(samples$rho_lamdaw)
rho_q <- mean(samples$rho_q)
rho_lamda_p <- mean(samples$rho_lamda_p)
rho_L <- mean(samples$rho_L)
```


```{r}
simulate_shock_and_update <- function(data, shock_time, shock_value, beta, gamma_pi, gamma_w, h, phi, sigma_L, rho_r, rho_pi, rho_y, r_y, r_pi, r_delta) {
  N <- data$T
  output_growth_shock <- data$output_growth_vector
  consumption_growth_shock <- data$consumption_growth_vector
  investment_growth_shock <- data$investment_growth_vector
  wage_growth_shock <- data$wage_growth_vector
  hours_shock <- data$hours_vector
  inflation_shock <- data$inflation_vector
  ffr_shock <- data$ffr_vector

  # Apply the shock to output growth
  output_growth_shock[shock_time] <- output_growth_shock[shock_time] * (1 - shock_value / 100)

  # Propagate the shock through the model
  for (t in (shock_time + 1):N) {
    # Example model equations to update other series based on the shocked output growth
    consumption_growth_shock[t] <- h * consumption_growth_shock[t-1] + beta * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
    investment_growth_shock[t] <- phi * investment_growth_shock[t-1] + beta * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
    wage_growth_shock[t] <- gamma_w * wage_growth_shock[t-1] + beta * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
    hours_shock[t] <- gamma_pi * hours_shock[t-1] + beta * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
    inflation_shock[t] <- gamma_pi * inflation_shock[t-1] + rho_pi * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
    ffr_shock[t] <- gamma_pi * ffr_shock[t-1] + rho_r * output_growth_shock[t-1] + rnorm(1, 0, sigma_L)
  }

  return(list(
    output_growth_shock = output_growth_shock,
    consumption_growth_shock = consumption_growth_shock,
    investment_growth_shock = investment_growth_shock,
    wage_growth_shock = wage_growth_shock,
    hours_shock = hours_shock,
    inflation_shock = inflation_shock,
    ffr_shock = ffr_shock
  ))
}

# Apply a 30% decrease shock at a specific time point (e.g., t = 50)
shock_time <- 50  # This is the time point at which the shock is applied
shock_value <- 30  # 30% decrease

# Simulate the shocked output growth and update other series
shocked_series <- simulate_shock_and_update(data_list, shock_time, shock_value, beta, gamma_pi, gamma_w, h, phi, sigma_L, rho_r, rho_pi, rho_y, r_y, r_pi, r_delta)

# Filter for finite values in all series
output_growth_finite <- data_list$output_growth_vector[is.finite(data_list$output_growth_vector)]
output_growth_shock_finite <- shocked_series$output_growth_shock[is.finite(shocked_series$output_growth_shock)]

consumption_growth_finite <- data_list$consumption_growth_vector[is.finite(data_list$consumption_growth_vector)]
consumption_growth_shock_finite <- shocked_series$consumption_growth_shock[is.finite(shocked_series$consumption_growth_shock)]

investment_growth_finite <- data_list$investment_growth_vector[is.finite(data_list$investment_growth_vector)]
investment_growth_shock_finite <- shocked_series$investment_growth_shock[is.finite(shocked_series$investment_growth_shock)]

wage_growth_finite <- data_list$wage_growth_vector[is.finite(data_list$wage_growth_vector)]
wage_growth_shock_finite <- shocked_series$wage_growth_shock[is.finite(shocked_series$wage_growth_shock)]

hours_finite <- data_list$hours_vector[is.finite(data_list$hours_vector)]
hours_shock_finite <- shocked_series$hours_shock[is.finite(shocked_series$hours_shock)]

inflation_finite <- data_list$inflation_vector[is.finite(data_list$inflation_vector)]
inflation_shock_finite <- shocked_series$inflation_shock[is.finite(shocked_series$inflation_shock)]

ffr_finite <- data_list$ffr_vector[is.finite(data_list$ffr_vector)]
ffr_shock_finite <- shocked_series$ffr_shock[is.finite(shocked_series$ffr_shock)]

# Plot with finite values
par(mfrow = c(2, 3))  # Arrange plots in a 2x3 grid

plot(consumption_growth_finite, type = "l", col = "blue", lty = 2, ylim = range(c(consumption_growth_finite, consumption_growth_shock_finite), na.rm = TRUE), ylab = "Consumption Growth", xlab = "Time")
lines(consumption_growth_shock_finite, col = "red")

plot(investment_growth_finite, type = "l", col = "blue", lty = 2, ylim = range(c(investment_growth_finite, investment_growth_shock_finite), na.rm = TRUE), ylab = "Investment Growth", xlab = "Time")
lines(investment_growth_shock_finite, col = "red")

plot(wage_growth_finite, type = "l", col = "blue", lty = 2, ylim = range(c(wage_growth_finite, wage_growth_shock_finite), na.rm = TRUE), ylab = "Wage Growth", xlab = "Time")
lines(wage_growth_shock_finite, col = "red")

plot(hours_finite, type = "l", col = "blue", lty = 2, ylim = range(c(hours_finite, hours_shock_finite), na.rm = TRUE), ylab = "Hours", xlab = "Time")
lines(hours_shock_finite, col = "red")

plot(inflation_finite, type = "l", col = "blue", lty = 2, ylim = range(c(inflation_finite, inflation_shock_finite), na.rm = TRUE), ylab = "Inflation", xlab = "Time")
lines(inflation_shock_finite, col = "red")

plot(ffr_finite, type = "l", col = "blue", lty = 2, ylim = range(c(ffr_finite, ffr_shock_finite), na.rm = TRUE), ylab = "Federal Funds Rate", xlab = "Time")
lines(ffr_shock_finite, col = "red")

```


```{r}

       library(ggplot2)
library(rstan)

# Set working directory
setwd("C:/Users/gealy/OneDrive/Documents/New folder (2)")

# Extract parameters in array form using as.array()
params <- as.array(fit)

# List of specific parameters to plot
selected_params <- c("Beta", "tao", "alpha", "psi", "gamma_pi", "gamma_w",
                     "lambda_w", "zeta_ps", "zeta_ws", "sigma_L", "sigma_c", 
                     "h", "phi", "phi_uppercase", "rbar_k", "Ky", "sigma_eta_C",
                     "Invy", "Cy", "gy", "r_pi", "r_y", "Ry_delta", "rho", 
                     "rho_el", "rho_ea", "rho_eb", "rho_G", "rho_pi", "rh_i", 
                     "rho_lamdaw", "rho_q", "rho_lamda_p", "rho_L")

# Get parameter names
param_names <- dimnames(params)[[3]]

# Loop through each parameter and generate plots only if it's in the selected_params list
for (param_name in param_names) {
    if (param_name %in% selected_params) {
        param_data <- params[, , param_name]
        
        # Create a data frame for ggplot
        param_df <- data.frame(
            Iteration = rep(1:dim(param_data)[1], each = dim(param_data)[2]),
            Value = as.vector(param_data),
            Chain = rep(1:dim(param_data)[2], each = dim(param_data)[1]),
            Parameter = param_name
        )
        
        # Generate the plot
        p <- ggplot(param_df, aes(x = Iteration, y = Value, color = as.factor(Chain))) +
            geom_line() +
            labs(title = paste("Trace Plot for", param_name), x = "Iteration", y = param_name) +
            theme_minimal()
        
        # Print the plot
        print(p)
        
        # Optionally, save the plot to a file
        ggsave(paste0("Trace_", param_name, ".png"), plot = p, width = 10, height = 8)
    }
}
   

```


```{r}
# Access data directly from the environment
beta_data <- get("Beta", envir = .GlobalEnv)

# Access data from the list
beta_data_from_list <- param_data_list[["Beta"]]

```

   

```{r}

library(actuar)
library(MASS)

data_list <- list(
  output_growth_vector = final$Output_growth,
  consumption_growth_vector = final$Consumption_growth,
  investment_growth_vector = final$Investment_growth,
  wage_growth_vector = final$Wage_growth,
  hours_vector = final$Hours,
  inflation_vector = final$Inflation,
  ffr_vector = final$Ffr,
  kapital = my_data$K_hat,
  q = my_data$Q_hat,
  c_epsilon=my_data$epsilon_C,
  g_epsilon=my_data$epsilon_G,
  i_epsilon=my_data$epsilon_I,
  w_epsilon=my_data$epsilon_W,
  pi_epsilon=my_data$epsilon_Pi,
  r_epsison=my_data$epsilon_R,
  w_epsilon=my_data$epsilon_W,
  r_epsilon=my_data$epsilon_R
)



results <- list()  # Initialize results storage

# Loop through each data vector in the list
for (data_name in names(data_list)) {
    cat("Optimizing for", data_name, "\n")
    
    # Extract the current data vector
    current_data <- data_list[[data_name]]
    
    # Check if the current data vector is non-empty and numeric
    if (length(current_data) > 0 && is.numeric(current_data)) {
        # Fit the normal distribution to the current data vector
        fit_normal <- fitdistr(current_data, densfun = "normal")

        # Store the results
        results[[data_name]] <- fit_normal
        
        # Print the estimated parameters
        cat(data_name, "Estimated mean:", fit_normal$estimate["mean"], 
            "Estimated sd:", fit_normal$estimate["sd"], "\n")
    } else {
        cat(data_name, "data is not a non-empty numeric vector.\n")
    }
}

```























